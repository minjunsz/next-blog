<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/d951632a592a525f.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d951632a592a525f.css" data-n-g=""/><link rel="preload" href="/_next/static/css/1a138e624f04d854.css" as="style"/><link rel="stylesheet" href="/_next/static/css/1a138e624f04d854.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-0d1b80a048d4787e.js"></script><script src="/_next/static/chunks/webpack-71e149bd9a6f2c0d.js" defer=""></script><script src="/_next/static/chunks/framework-3b7283d6a8166ac6.js" defer=""></script><script src="/_next/static/chunks/main-f86807978e025087.js" defer=""></script><script src="/_next/static/chunks/pages/_app-3109e2f73342e24b.js" defer=""></script><script src="/_next/static/chunks/175675d1-77a9baecceeabeea.js" defer=""></script><script src="/_next/static/chunks/996-343ac9394dcb133e.js" defer=""></script><script src="/_next/static/chunks/981-607a7e5dc5e30fb0.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-7f4e1b9940fe9a91.js" defer=""></script><script src="/_next/static/VaUQGDqs_MWm1pJur4D7C/_buildManifest.js" defer=""></script><script src="/_next/static/VaUQGDqs_MWm1pJur4D7C/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="dark"><div class="bg-zinc-100 text-neutral-700 dark:bg-zinc-900 dark:text-neutral-300 min-h-screen flex flex-col"><nav class="bg-gray-300 border-gray-200 px-2 sm:px-4 py-2.5 rounded dark:bg-stone-700"><div class="container flex flex-wrap justify-between items-center mx-auto max-w-5xl"><span class="flex items-center cursor-pointer"><img src="favicon.ico" class="mr-3 h-6 sm:h-9" alt="Flowbite Logo"/><span class="self-center text-xl font-semibold whitespace-nowrap dark:text-white">Minjun Blog</span></span><div class="flex justify-end items-center"><button id="theme-toggle" type="button" class="text-gray-700 dark:text-gray-200 hover:bg-gray-200 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:hover:bg-gray-700 dark:focus:ring-gray-600 rounded-lg text-sm p-2.5"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-5 text-normal-text dark:text-off-white inline-block dark:hidden"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="w-5 text-normal-text dark:text-off-white hidden dark:inline-block"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg></button><button data-collapse-toggle="mobile-menu" type="button" class="inline-flex items-center p-2 ml-3 text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-200 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-600" aria-controls="mobile-menu" aria-expanded="false"><span class="sr-only">Open main menu</span><svg class="w-6 h-6" aria-hidden="true" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg><svg class="hidden w-6 h-6" aria-hidden="true" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button><div class="w-full md:w-auto hidden md:block p-2 ml-3" id="large-menu"><ul class="flex flex-col mt-4 md:flex-row md:space-x-8 md:mt-0 md:text-sm md:font-medium"><li><span class="block py-2 pr-4 pl-3 text-gray-700 hover:bg-gray-50 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-gray-400 md:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent cursor-pointer">About</span></li><li><span class="block py-2 pr-4 pl-3 text-gray-700 hover:bg-gray-50 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-gray-400 md:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent cursor-pointer">Blog</span></li></ul></div></div><div class="w-full md:w-auto hidden" id="mobile-menu"><ul class="flex flex-col mt-4 md:flex-row md:space-x-8 md:mt-0 md:text-sm md:font-medium"><li><span class="block py-2 pr-4 pl-3 text-gray-700 hover:bg-gray-50 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-gray-400 md:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent cursor-pointer">About</span></li><li><span class="block py-2 pr-4 pl-3 text-gray-700 hover:bg-gray-50 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-gray-400 md:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent cursor-pointer">Blog</span></li></ul></div></div></nav><div class="flex-grow flex flex-col"><div class="flex-grow flex justify-center"><div class="max-w-5xl w-full bg-zinc-200 dark:bg-zinc-800 p-4 md:px-14"><div class="block px-2 lg:flex"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27140%27%20height=%27140%27/%3e"/></span><img alt="Profile Image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="rounded-full" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="Profile Image" src="/profile.jpg" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-full" loading="lazy"/></noscript></span><div class="flex flex-col justify-center py-4 lg:py-0 lg:px-6"><div class="text-2xl font-bold">Hello, I&#x27;m Minjun</div><div>I try to post what I&#x27;ve studied about machine learning. I generally write about Generative Models, Graph Learning, ML Engineering.</div></div></div><div class="lg:flex lg:flex-row-reverse lg:justify-between"><div class="lg:w-1/3 lg:h-screen lg:sticky lg:top-10"><div class="lg:pl-7 lg:pt-10"><nav aria-label="Table of Contents" class="w-fit"><div class="font-bold text-neutral-500 dark:text-neutral-400">What&#x27;s on this Page</div><ul></ul></nav></div></div><div class="w-full lg:flex-grow px-4 mt-4 rounded-md bg-stone-300 dark:bg-stone-700"><div class="markdown-body Markdown_markdown__vyKqn"><h1 id="pytorch-lightning-사용법">Pytorch Lightning 사용법</h1>
<p>Pytorch lightning에서 핵심 개념은 <strong>LightningModule</strong>과 <strong>Trainer</strong>이다.<br/>
<code node="[object Object]">LightningModule</code>에서는 실제로 ML Model을 정의하는 것에 초점을 두는 반면<br/>
<code node="[object Object]">Trainer</code>는 model을 학습시키고 저장하는 등의 engineering에 초점을 둔다.</p>
<p>추가적으로 핵심 module은 아니지만 <strong>Callback</strong>, <strong>LightningDataModule</strong>을 정의해 사용할 수 있다.</p>
<ul>
<li>Model 구조 (research 관련) -&gt; <code node="[object Object]">LightningModule</code></li>
<li>Engineering 관련 -&gt; <code node="[object Object]">Trainer</code></li>
<li>데이터 처리 -&gt; <code node="[object Object]">LightningDataModule</code></li>
<li>기타 재사용 가능 코드 -&gt; <code node="[object Object]">Callback</code></li>
</ul>
<h2 id="pllightningmodule-정의">pl.LightningModule 정의</h2>
<p>Pytorch lightning은 전체 코드를 작은 함수 단위로 쪼개 쓰도록 해준다.<br/>
<!-- -->구조가 잘 잡힌 프로그램을 짜기 위해 pl.LightningModule 내에 정의돼있는<br/>
<!-- -->함수들을 overriding해서 사용하므로 <strong>꼭 함수 이름을 맞춰주도록</strong> 한다.</p>
<p><code node="[object Object]">pl.LightningModule</code>의 경우 <code node="[object Object]">nn.Module</code>을 상속받는 Wrapper class이긴 하지만 기존의 <code node="[object Object]">nn.Module</code>이 단순히 ML model만을 정의했다면 <code node="[object Object]">pl.LightningModule</code>은 loss, optimizer, 원한다면 data까지를 모두 포함하는 system을 정의한다.</p>
<p>code는 6개의 section이 있다.</p>
<ul>
<li>Computations (init).</li>
<li>Train Loop (training_step)</li>
<li>Validation Loop (validation_step)</li>
<li>Test Loop (test_step)</li>
<li>Prediction Loop (predict_step)</li>
<li>Optimizers and LR Schedulers (configure_optimizers)</li>
</ul>
<h3 id="실제-model-구현-작업-순서">실제 model 구현 작업 순서</h3>
<ol>
<li>
<p>기존의 __init__(), forward() 함수는 그대로 유지한다.<br/>
<!-- -->pytorch lightning에서 forward 함수는 &#x27;inference / prediction&#x27;등의 작업을 정의하는 곳이다. train 과정에 필요한 내용은 <code node="[object Object]">training_step()</code>함수에 포함시키고 <code node="[object Object]">forward()</code>함수에는 들어가지 않도록 한다.</p>
</li>
<li>
<p><strong>training_step()</strong> 함수 구현<br/>
<!-- -->기존의 train loop 내에서 loss를 구하는 것 까지만 진행한 뒤 &quot;loss&quot;를 포함하는 dictionary return<br/>
<!-- -->parameter로 batch, batch_idx를 받는다</p>
<pre><div node="[object Object]" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em;background:#1d1f21"><code class="language-python" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">training_step</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">,</span><span> batch</span><span class="token" style="color:#c5c8c6">,</span><span> batch_idx</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>  x</span><span class="token" style="color:#c5c8c6">,</span><span> y </span><span class="token" style="color:#EDEDED">=</span><span> batch
</span></span><span><span>  output </span><span class="token" style="color:#EDEDED">=</span><span> self</span><span class="token" style="color:#c5c8c6">(</span><span>x</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>  loss </span><span class="token" style="color:#EDEDED">=</span><span> F</span><span class="token" style="color:#c5c8c6">.</span><span>cross_entropy</span><span class="token" style="color:#c5c8c6">(</span><span>output</span><span class="token" style="color:#c5c8c6">,</span><span> y</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>  </span><span class="token" style="color:#7C7C7C"># logging statement</span><span>
</span></span><span><span>  </span><span class="token" style="color:#96CBFE">return</span><span> </span><span class="token" style="color:#c5c8c6">{</span><span class="token" style="color:#A8FF60">&quot;loss&quot;</span><span class="token" style="color:#c5c8c6">:</span><span> loss</span><span class="token" style="color:#c5c8c6">,</span><span> </span><span class="token" style="color:#A8FF60">&quot;additional info&quot;</span><span class="token" style="color:#c5c8c6">:</span><span> </span><span class="token" style="color:#c5c8c6">.</span><span class="token" style="color:#c5c8c6">.</span><span class="token" style="color:#c5c8c6">.</span><span class="token" style="color:#c5c8c6">}</span></span></code></div></pre>
<!-- -->&lt;span&gt;
epoch level의 logging이 필요하다면 self.log()를 이용한다. batch별 값을 종합한 결과를 log할 수 있다. log 외에 epoch별로 해야하는 작업이 있다면 `training_epoch_end()` 등의 함수를 사용한다.&lt;br&gt;<!-- -->
<pre><div node="[object Object]" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em;background:#1d1f21"><code class="language-python" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">training_step</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">,</span><span> batch</span><span class="token" style="color:#c5c8c6">,</span><span> batch_idx</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>  </span><span class="token" style="color:#c5c8c6">.</span><span class="token" style="color:#c5c8c6">.</span><span class="token" style="color:#c5c8c6">.</span><span>
</span></span><span><span>  </span><span class="token" style="color:#7C7C7C"># logs metrics for each training_step,</span><span>
</span></span><span><span>  </span><span class="token" style="color:#7C7C7C"># and the average across the epoch, to the progress bar and logger</span><span>
</span></span><span><span>  self</span><span class="token" style="color:#c5c8c6">.</span><span>log</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#A8FF60">&quot;train_loss&quot;</span><span class="token" style="color:#c5c8c6">,</span><span> loss</span><span class="token" style="color:#c5c8c6">,</span><span> on_step</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">True</span><span class="token" style="color:#c5c8c6">,</span><span> on_epoch</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">True</span><span class="token" style="color:#c5c8c6">,</span><span> prog_bar</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">True</span><span class="token" style="color:#c5c8c6">,</span><span> logger</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">True</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>  </span><span class="token" style="color:#96CBFE">return</span><span> loss
</span></span><span><span>  </span><span class="token" style="color:#7C7C7C"># ========================= or =========================</span><span>
</span></span><span><span>  </span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">training_step</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">,</span><span> batch</span><span class="token" style="color:#c5c8c6">,</span><span> batch_idx</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>    </span><span class="token" style="color:#c5c8c6">.</span><span class="token" style="color:#c5c8c6">.</span><span class="token" style="color:#c5c8c6">.</span><span>
</span></span><span><span>    </span><span class="token" style="color:#96CBFE">return</span><span> </span><span class="token" style="color:#c5c8c6">{</span><span class="token" style="color:#A8FF60">&quot;loss&quot;</span><span class="token" style="color:#c5c8c6">:</span><span> loss</span><span class="token" style="color:#c5c8c6">,</span><span> </span><span class="token" style="color:#A8FF60">&quot;other_stuff&quot;</span><span class="token" style="color:#c5c8c6">:</span><span> preds</span><span class="token" style="color:#c5c8c6">}</span><span>
</span></span><span>
</span><span><span>  </span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">training_epoch_end</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">,</span><span> training_step_outputs</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>    all_preds </span><span class="token" style="color:#EDEDED">=</span><span> torch</span><span class="token" style="color:#c5c8c6">.</span><span>stack</span><span class="token" style="color:#c5c8c6">(</span><span>training_step_outputs</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>    </span><span class="token" style="color:#c5c8c6">.</span><span class="token" style="color:#c5c8c6">.</span><span class="token" style="color:#c5c8c6">.</span></span></code></div></pre>
</li>
<li>
<p><strong>configure_optimizer()</strong> 함수 구현</p>
<pre><div node="[object Object]" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em;background:#1d1f21"><code class="language-python" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">configure_optimizer</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>  </span><span class="token" style="color:#96CBFE">return</span><span> torch</span><span class="token" style="color:#c5c8c6">.</span><span>optim</span><span class="token" style="color:#c5c8c6">.</span><span>Adam</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>parameters</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">,</span><span> lr</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">0.001</span><span class="token" style="color:#c5c8c6">)</span></span></code></div></pre>
</li>
<li>
<p>hook 사용
train / validation / test / predict 각 단계별로 3종류의 hook을 사용할 수 있다.</p>
<ul>
<li>x_step</li>
<li>x_step_end (optional)</li>
<li>x_epoch_end (optional)
위의 <code node="[object Object]">training_step</code>을 정의하던 것과 같이 각 step은 필수적으로 구현되어야하며 각 batch별로, epoch별로 추가적인 기능을 구현할 수 있다.<br/>
<!-- -->hook별 interface는 필요할 때 공식 document를 참고해서 작성하자.</li>
</ul>
</li>
</ol>
<h2 id="trainer-정의">Trainer 정의</h2>
<p>기본적인 사용 방법은 Trainer를 정의하고 <code node="[object Object]">trainer.fit()</code>함수에 model, dataloader를 넣어주면 학습이 진행된다.</p>
<pre><div node="[object Object]" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em;background:#1d1f21"><code class="language-python" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span><span>trainer </span><span class="token" style="color:#EDEDED">=</span><span> Trainer</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>model </span><span class="token" style="color:#EDEDED">=</span><span> LitModel</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>trainer</span><span class="token" style="color:#c5c8c6">.</span><span>fit</span><span class="token" style="color:#c5c8c6">(</span><span>model</span><span class="token" style="color:#EDEDED">=</span><span>model</span><span class="token" style="color:#c5c8c6">,</span><span> train_dataloaders</span><span class="token" style="color:#EDEDED">=</span><span>train_loader</span><span class="token" style="color:#c5c8c6">)</span></span></code></div></pre>
<!-- -->&lt;span&gt;
Trainer를 통해 계산에 사용될 device를 결정할 수 있다.
이렇게 device를 선택할 경우 기존의 model.to(device), tensor.to(device) 작업을 pytorch lightning이 알아서 작업해준다.<!-- -->
<pre><div node="[object Object]" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em;background:#1d1f21"><code class="language-python" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span><span>
</span></span><span><span></span><span class="token" style="color:#7C7C7C"># train on CPU</span><span>
</span></span><span><span>trainer </span><span class="token" style="color:#EDEDED">=</span><span> Trainer</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>trainer </span><span class="token" style="color:#EDEDED">=</span><span> Trainer</span><span class="token" style="color:#c5c8c6">(</span><span>accelerator</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#A8FF60">&quot;cpu&quot;</span><span class="token" style="color:#c5c8c6">,</span><span> devices</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">8</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span>
</span><span><span></span><span class="token" style="color:#7C7C7C"># train on 1 GPU</span><span>
</span></span><span><span>trainer </span><span class="token" style="color:#EDEDED">=</span><span> pl</span><span class="token" style="color:#c5c8c6">.</span><span>Trainer</span><span class="token" style="color:#c5c8c6">(</span><span>accelerator</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#A8FF60">&quot;gpu&quot;</span><span class="token" style="color:#c5c8c6">,</span><span> devices</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">1</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span>
</span><span><span></span><span class="token" style="color:#7C7C7C"># Train on 8 TPU cores</span><span>
</span></span><span><span>trainer </span><span class="token" style="color:#EDEDED">=</span><span> pl</span><span class="token" style="color:#c5c8c6">.</span><span>Trainer</span><span class="token" style="color:#c5c8c6">(</span><span>accelerator</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#A8FF60">&quot;tpu&quot;</span><span class="token" style="color:#c5c8c6">,</span><span> devices</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">8</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span></span></code></div></pre>
<h3 id="debugging">debugging</h3>
<p>Trainer가 제공하는 다양한 기능 중 실제로 model 구현하며 debugging에 도움되는 기능들이 존재한다. 나는 실제 프로그래밍 중에는 <code node="[object Object]">fast_dev_run</code> -&gt; <code node="[object Object]">overfit_batches</code> -&gt; <code node="[object Object]">val_check_interval</code> 의 순서로 사용한다.</p>
<ul>
<li>
<p>일부 batch만 학습</p>
<pre><div node="[object Object]" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em;background:#1d1f21"><code class="language-python" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span><span>  Trainer</span><span class="token" style="color:#c5c8c6">(</span><span>limit_train_batches</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">10</span><span class="token" style="color:#c5c8c6">,</span><span> limit_val_batches</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">3</span><span class="token" style="color:#c5c8c6">)</span></span></code></div></pre>
</li>
<li>
<p>일부 batch에대해 overfit 하여 모델이 정상적으로 학습되는지 sanity check</p>
<pre><div node="[object Object]" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em;background:#1d1f21"><code class="language-python" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span><span>  Trainer</span><span class="token" style="color:#c5c8c6">(</span><span>overfit_batches</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">10</span><span class="token" style="color:#c5c8c6">)</span></span></code></div></pre>
</li>
<li>
<p>코드상의 모든 지점을 통과하도록 최소한의 batch, epoch으로 진행</p>
<pre><div node="[object Object]" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em;background:#1d1f21"><code class="language-python" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span><span>  </span><span class="token" style="color:#7C7C7C"># 모든 코드를 1번씩 통과시키는 unit test</span><span>
</span></span><span><span>  Trainer</span><span class="token" style="color:#c5c8c6">(</span><span>fast_dev_run</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">True</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>  </span><span class="token" style="color:#7C7C7C"># 모든 코드를 4번씩 통과시키는 unit test</span><span>
</span></span><span><span>  Trainer</span><span class="token" style="color:#c5c8c6">(</span><span>fast_Dev_run</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">4</span><span class="token" style="color:#c5c8c6">)</span></span></code></div></pre>
</li>
<li>
<p>구간별로 validation 진행
일반적으로는 <em>train loop에 N번째 epoch마다 validation을 해라.</em> 라는 형태로 코드를 작성하며 train / validate 코드가 합쳐졌었는데 이 logic을 분리할 수 있다. validation step은 model에 작성하고 언제 validation을 실행할지는 trainer에 명시해주면 된다.</p>
<pre><div node="[object Object]" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em;background:#1d1f21"><code class="language-python" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span><span>  </span><span class="token" style="color:#7C7C7C"># epoch 25% 했을때마다 validation 진행</span><span>
</span></span><span><span>  Trainer</span><span class="token" style="color:#c5c8c6">(</span><span>val_check_interval</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">0.25</span><span class="token" style="color:#c5c8c6">)</span></span></code></div></pre>
</li>
</ul>
<h3 id="기타-기능들">기타 기능들</h3>
<ul>
<li>argparser 사용</li>
<li>precision 선택</li>
<li>callback, 이를 이용한 checkpoint 저장</li>
<li>gradient clipping</li>
<li>logger 등록</li>
<li>terminate_on_nan</li>
<li>profiler 등록</li>
</ul>
<h2 id="pllightningdatamodule-정의">pl.LightningDataModule 정의</h2>
<p>data loading은 <code node="[object Object]">LightningModule</code> 내에 함께 정의할 수 있지만 <code node="[object Object]">LightningDataModule</code>을 별도로 정의함으로써 더 모듈화되고 재사용가능한 코드를 작성할 수 있다.<br/>
<code node="[object Object]">LightningDataModule</code>은 train / val / test / prediction dataloader의 collection이며 각 단계에 해당하는 download, preprocessing, transform을 함께 정의한다.</p>
<ol>
<li><code node="[object Object]">prepare_data()</code>: single process에서 진행돼야하는 작업을 정의한다. (data download, tokenize)</li>
<li><code node="[object Object]">setup</code>: 각 GPU에서 개별적으로 실시돼야하는 operation을 정의한다. (data split, create dataset, apply transform)</li>
<li><code node="[object Object]">x_dataloader</code>: 각 stage별로 dataset -&gt; dataloader를 반환하는 코드를 작성한다.</li>
</ol>
<pre><div node="[object Object]" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:.5em 0;overflow:auto;border-radius:0.3em;background:#1d1f21"><code class="language-python" style="color:#c5c8c6;text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:Inconsolata, Monaco, Consolas, &#x27;Courier New&#x27;, Courier, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span><span class="token" style="color:#96CBFE">import</span><span> pytorch_lightning </span><span class="token" style="color:#96CBFE">as</span><span> pl
</span></span><span><span></span><span class="token" style="color:#96CBFE">from</span><span> torch</span><span class="token" style="color:#c5c8c6">.</span><span>utils</span><span class="token" style="color:#c5c8c6">.</span><span>data </span><span class="token" style="color:#96CBFE">import</span><span> random_split</span><span class="token" style="color:#c5c8c6">,</span><span> DataLoader
</span></span><span>
</span><span><span></span><span class="token" style="color:#7C7C7C"># Note - you must have torchvision installed for this example</span><span>
</span></span><span><span></span><span class="token" style="color:#96CBFE">from</span><span> torchvision</span><span class="token" style="color:#c5c8c6">.</span><span>datasets </span><span class="token" style="color:#96CBFE">import</span><span> MNIST
</span></span><span><span></span><span class="token" style="color:#96CBFE">from</span><span> torchvision </span><span class="token" style="color:#96CBFE">import</span><span> transforms
</span></span><span>
</span><span>
</span><span><span></span><span class="token" style="color:#96CBFE">class</span><span> </span><span class="token" style="color:#FFFFB6;text-decoration:underline">MNISTDataModule</span><span class="token" style="color:#c5c8c6">(</span><span>pl</span><span class="token" style="color:#c5c8c6">.</span><span>LightningDataModule</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>    </span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">__init__</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">,</span><span> data_dir</span><span class="token" style="color:#c5c8c6">:</span><span> </span><span class="token" style="color:#A8FF60">str</span><span> </span><span class="token" style="color:#EDEDED">=</span><span> </span><span class="token" style="color:#A8FF60">&quot;./&quot;</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>        </span><span class="token" style="color:#A8FF60">super</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">.</span><span>__init__</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>        self</span><span class="token" style="color:#c5c8c6">.</span><span>data_dir </span><span class="token" style="color:#EDEDED">=</span><span> data_dir
</span></span><span><span>        self</span><span class="token" style="color:#c5c8c6">.</span><span>transform </span><span class="token" style="color:#EDEDED">=</span><span> transforms</span><span class="token" style="color:#c5c8c6">.</span><span>Compose</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#c5c8c6">[</span><span>transforms</span><span class="token" style="color:#c5c8c6">.</span><span>ToTensor</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">,</span><span> transforms</span><span class="token" style="color:#c5c8c6">.</span><span>Normalize</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#FF73FD">0.1307</span><span class="token" style="color:#c5c8c6">,</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">,</span><span> </span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#FF73FD">0.3081</span><span class="token" style="color:#c5c8c6">,</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">]</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span>
</span><span><span>    </span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">prepare_data</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>        </span><span class="token" style="color:#7C7C7C"># download</span><span>
</span></span><span><span>        MNIST</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>data_dir</span><span class="token" style="color:#c5c8c6">,</span><span> train</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">True</span><span class="token" style="color:#c5c8c6">,</span><span> download</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">True</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>        MNIST</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>data_dir</span><span class="token" style="color:#c5c8c6">,</span><span> train</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">False</span><span class="token" style="color:#c5c8c6">,</span><span> download</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">True</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span>
</span><span><span>    </span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">setup</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">,</span><span> stage</span><span class="token" style="color:#c5c8c6">:</span><span> Optional</span><span class="token" style="color:#c5c8c6">[</span><span class="token" style="color:#A8FF60">str</span><span class="token" style="color:#c5c8c6">]</span><span> </span><span class="token" style="color:#EDEDED">=</span><span> </span><span class="token" style="color:#99CC99">None</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span>
</span><span><span>        </span><span class="token" style="color:#7C7C7C"># Assign train/val datasets for use in dataloaders</span><span>
</span></span><span><span>        </span><span class="token" style="color:#96CBFE">if</span><span> stage </span><span class="token" style="color:#96CBFE">in</span><span> </span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#A8FF60">&quot;fit&quot;</span><span class="token" style="color:#c5c8c6">,</span><span> </span><span class="token" style="color:#A8FF60">&quot;validate&quot;</span><span class="token" style="color:#c5c8c6">,</span><span> </span><span class="token" style="color:#99CC99">None</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>            mnist_full </span><span class="token" style="color:#EDEDED">=</span><span> MNIST</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>data_dir</span><span class="token" style="color:#c5c8c6">,</span><span> train</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">True</span><span class="token" style="color:#c5c8c6">,</span><span> transform</span><span class="token" style="color:#EDEDED">=</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>transform</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span><span>            self</span><span class="token" style="color:#c5c8c6">.</span><span>mnist_train</span><span class="token" style="color:#c5c8c6">,</span><span> self</span><span class="token" style="color:#c5c8c6">.</span><span>mnist_val </span><span class="token" style="color:#EDEDED">=</span><span> random_split</span><span class="token" style="color:#c5c8c6">(</span><span>mnist_full</span><span class="token" style="color:#c5c8c6">,</span><span> </span><span class="token" style="color:#c5c8c6">[</span><span class="token" style="color:#FF73FD">55000</span><span class="token" style="color:#c5c8c6">,</span><span> </span><span class="token" style="color:#FF73FD">5000</span><span class="token" style="color:#c5c8c6">]</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span>
</span><span><span>        </span><span class="token" style="color:#7C7C7C"># Assign test dataset for use in dataloader(s)</span><span>
</span></span><span><span>        </span><span class="token" style="color:#96CBFE">if</span><span> stage </span><span class="token" style="color:#96CBFE">in</span><span> </span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#A8FF60">&quot;test&quot;</span><span class="token" style="color:#c5c8c6">,</span><span> </span><span class="token" style="color:#99CC99">None</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>            self</span><span class="token" style="color:#c5c8c6">.</span><span>mnist_test </span><span class="token" style="color:#EDEDED">=</span><span> MNIST</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>data_dir</span><span class="token" style="color:#c5c8c6">,</span><span> train</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">False</span><span class="token" style="color:#c5c8c6">,</span><span> transform</span><span class="token" style="color:#EDEDED">=</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>transform</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span>
</span><span><span>        </span><span class="token" style="color:#96CBFE">if</span><span> stage </span><span class="token" style="color:#96CBFE">in</span><span> </span><span class="token" style="color:#c5c8c6">(</span><span class="token" style="color:#A8FF60">&quot;predict&quot;</span><span class="token" style="color:#c5c8c6">,</span><span> </span><span class="token" style="color:#99CC99">None</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>            self</span><span class="token" style="color:#c5c8c6">.</span><span>mnist_predict </span><span class="token" style="color:#EDEDED">=</span><span> MNIST</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>data_dir</span><span class="token" style="color:#c5c8c6">,</span><span> train</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#99CC99">False</span><span class="token" style="color:#c5c8c6">,</span><span> transform</span><span class="token" style="color:#EDEDED">=</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>transform</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span>
</span><span><span>    </span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">train_dataloader</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>        </span><span class="token" style="color:#96CBFE">return</span><span> DataLoader</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>mnist_train</span><span class="token" style="color:#c5c8c6">,</span><span> batch_size</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">32</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span>
</span><span><span>    </span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">val_dataloader</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>        </span><span class="token" style="color:#96CBFE">return</span><span> DataLoader</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>mnist_val</span><span class="token" style="color:#c5c8c6">,</span><span> batch_size</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">32</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span>
</span><span><span>    </span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">test_dataloader</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>        </span><span class="token" style="color:#96CBFE">return</span><span> DataLoader</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>mnist_test</span><span class="token" style="color:#c5c8c6">,</span><span> batch_size</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">32</span><span class="token" style="color:#c5c8c6">)</span><span>
</span></span><span>
</span><span><span>    </span><span class="token" style="color:#96CBFE">def</span><span> </span><span class="token" style="color:#DAD085">predict_dataloader</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">)</span><span class="token" style="color:#c5c8c6">:</span><span>
</span></span><span><span>        </span><span class="token" style="color:#96CBFE">return</span><span> DataLoader</span><span class="token" style="color:#c5c8c6">(</span><span>self</span><span class="token" style="color:#c5c8c6">.</span><span>mnist_predict</span><span class="token" style="color:#c5c8c6">,</span><span> batch_size</span><span class="token" style="color:#EDEDED">=</span><span class="token" style="color:#FF73FD">32</span><span class="token" style="color:#c5c8c6">)</span></span></code></div></pre>
<h2 id="weights--biases-연동하기">Weights &amp; Biases 연동하기</h2>
<p>pytorch lightning은 자체적으로 <code node="[object Object]">WandbLogger</code>를 지원하므로 간단하게 logging, model 저장을 할 수 있다.<br/>
<a href="https://wandb.ai/wandb_fc/korean/reports/Weights-Biases-Pytorch-Lightning---VmlldzozNzAxOTg">W&amp;B 공식 post</a>에 필요한 내용과 code들이 수록돼있으니 참고해서 작성하자.</p>
<h2 id="도움될-document-모음">도움될 document 모음</h2>
<p><a href="https://colab.research.google.com/drive/1rHBxrtopwtF8iLpmC_e7yl3TeDGrseJL?usp=sharing%3E">prototyping에 사용하기 좋은 template colab notebook</a><br/>
<a href="https://pytorch-lightning.readthedocs.io/en/stable/common/early_stopping.html">early stopping을 사용하는 경우 callback 등록</a><br/>
<a href="https://pytorch-lightning.readthedocs.io/en/stable/common/optimization.html#id4">GAN에서 여러 optimizer를 순서대로 실행시키는 경우</a><br/>
<a href="https://pytorch-lightning.readthedocs.io/en/stable/advanced/training_tricks.html#batch-size-finder">자동으로 최대 batch size 찾기</a><br/>
<a href="https://pytorch-lightning.readthedocs.io/en/stable/advanced/training_tricks.html#learning-rate-finder">자동으로 learning rate 찾기</a></p></div></div></div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"frontMatter":{"title":"Pytorch Lightning","excerpt":"Pytorch Lightning은 기존의 pytorch 코드를 기능별로 분리해주며 research / engineer을 명확히 구분해준다.","tags":["Pytorch Lightning","Framework"],"publishedDate":"Sun May 01 2022 00:00:00 GMT+0000 (Coordinated Universal Time)"},"markdownBody":"\n# Pytorch Lightning 사용법\n\nPytorch lightning에서 핵심 개념은 **LightningModule**과 **Trainer**이다.  \n`LightningModule`에서는 실제로 ML Model을 정의하는 것에 초점을 두는 반면  \n`Trainer`는 model을 학습시키고 저장하는 등의 engineering에 초점을 둔다.\n\n추가적으로 핵심 module은 아니지만 **Callback**, **LightningDataModule**을 정의해 사용할 수 있다.\n\n- Model 구조 (research 관련) -\u003e `LightningModule`\n- Engineering 관련 -\u003e `Trainer`\n- 데이터 처리 -\u003e `LightningDataModule`\n- 기타 재사용 가능 코드 -\u003e `Callback`\n\n## pl.LightningModule 정의\n\nPytorch lightning은 전체 코드를 작은 함수 단위로 쪼개 쓰도록 해준다.  \n구조가 잘 잡힌 프로그램을 짜기 위해 pl.LightningModule 내에 정의돼있는  \n함수들을 overriding해서 사용하므로 **꼭 함수 이름을 맞춰주도록** 한다.\n\n`pl.LightningModule`의 경우 `nn.Module`을 상속받는 Wrapper class이긴 하지만 기존의 `nn.Module`이 단순히 ML model만을 정의했다면 `pl.LightningModule`은 loss, optimizer, 원한다면 data까지를 모두 포함하는 system을 정의한다.\n\ncode는 6개의 section이 있다.\n\n- Computations (init).\n- Train Loop (training_step)\n- Validation Loop (validation_step)\n- Test Loop (test_step)\n- Prediction Loop (predict_step)\n- Optimizers and LR Schedulers (configure_optimizers)\n\n### 실제 model 구현 작업 순서\n\n1. 기존의 \\_\\_init\\_\\_(), forward() 함수는 그대로 유지한다.  \n   pytorch lightning에서 forward 함수는 'inference / prediction'등의 작업을 정의하는 곳이다. train 과정에 필요한 내용은 `training_step()`함수에 포함시키고 `forward()`함수에는 들어가지 않도록 한다.\n2. **training_step()** 함수 구현  \n   기존의 train loop 내에서 loss를 구하는 것 까지만 진행한 뒤 \"loss\"를 포함하는 dictionary return  \n   parameter로 batch, batch_idx를 받는다\n\n   ```python\n   def training_step(self, batch, batch_idx)\n     x, y = batch\n     output = self(x)\n     loss = F.cross_entropy(output, y)\n     # logging statement\n     return {\"loss\": loss, \"additional info\": ...}\n   ```\n\n   \u003cspan\u003e\n   epoch level의 logging이 필요하다면 self.log()를 이용한다. batch별 값을 종합한 결과를 log할 수 있다. log 외에 epoch별로 해야하는 작업이 있다면 `training_epoch_end()` 등의 함수를 사용한다.\u003cbr\u003e\n\n   ```python\n   def training_step(self, batch, batch_idx):\n     ...\n     # logs metrics for each training_step,\n     # and the average across the epoch, to the progress bar and logger\n     self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n     return loss\n     # ========================= or =========================\n     def training_step(self, batch, batch_idx):\n       ...\n       return {\"loss\": loss, \"other_stuff\": preds}\n\n     def training_epoch_end(self, training_step_outputs):\n       all_preds = torch.stack(training_step_outputs)\n       ...\n   ```\n\n3. **configure_optimizer()** 함수 구현\n\n   ```python\n   def configure_optimizer():\n     return torch.optim.Adam(self.parameters(), lr=0.001)\n   ```\n\n4. hook 사용\n   train / validation / test / predict 각 단계별로 3종류의 hook을 사용할 수 있다.\n   - x_step\n   - x_step_end (optional)\n   - x_epoch_end (optional)\n     위의 `training_step`을 정의하던 것과 같이 각 step은 필수적으로 구현되어야하며 각 batch별로, epoch별로 추가적인 기능을 구현할 수 있다.  \n     hook별 interface는 필요할 때 공식 document를 참고해서 작성하자.\n\n## Trainer 정의\n\n기본적인 사용 방법은 Trainer를 정의하고 `trainer.fit()`함수에 model, dataloader를 넣어주면 학습이 진행된다.\n\n```python\ntrainer = Trainer()\nmodel = LitModel()\ntrainer.fit(model=model, train_dataloaders=train_loader)\n```\n\n\u003cspan\u003e\nTrainer를 통해 계산에 사용될 device를 결정할 수 있다.\n이렇게 device를 선택할 경우 기존의 model.to(device), tensor.to(device) 작업을 pytorch lightning이 알아서 작업해준다.\n\n```python\n\n# train on CPU\ntrainer = Trainer()\ntrainer = Trainer(accelerator=\"cpu\", devices=8)\n\n# train on 1 GPU\ntrainer = pl.Trainer(accelerator=\"gpu\", devices=1)\n\n# Train on 8 TPU cores\ntrainer = pl.Trainer(accelerator=\"tpu\", devices=8)\n\n```\n\n### debugging\n\nTrainer가 제공하는 다양한 기능 중 실제로 model 구현하며 debugging에 도움되는 기능들이 존재한다. 나는 실제 프로그래밍 중에는 `fast_dev_run` -\u003e `overfit_batches` -\u003e `val_check_interval` 의 순서로 사용한다.\n\n- 일부 batch만 학습\n\n  ```python\n    Trainer(limit_train_batches=10, limit_val_batches=3)\n  ```\n\n- 일부 batch에대해 overfit 하여 모델이 정상적으로 학습되는지 sanity check\n\n  ```python\n    Trainer(overfit_batches=10)\n  ```\n\n- 코드상의 모든 지점을 통과하도록 최소한의 batch, epoch으로 진행\n\n  ```python\n    # 모든 코드를 1번씩 통과시키는 unit test\n    Trainer(fast_dev_run=True)\n    # 모든 코드를 4번씩 통과시키는 unit test\n    Trainer(fast_Dev_run=4)\n  ```\n\n- 구간별로 validation 진행\n  일반적으로는 _train loop에 N번째 epoch마다 validation을 해라._ 라는 형태로 코드를 작성하며 train / validate 코드가 합쳐졌었는데 이 logic을 분리할 수 있다. validation step은 model에 작성하고 언제 validation을 실행할지는 trainer에 명시해주면 된다.\n\n  ```python\n    # epoch 25% 했을때마다 validation 진행\n    Trainer(val_check_interval=0.25)\n  ```\n\n### 기타 기능들\n\n- argparser 사용\n- precision 선택\n- callback, 이를 이용한 checkpoint 저장\n- gradient clipping\n- logger 등록\n- terminate_on_nan\n- profiler 등록\n\n## pl.LightningDataModule 정의\n\ndata loading은 `LightningModule` 내에 함께 정의할 수 있지만 `LightningDataModule`을 별도로 정의함으로써 더 모듈화되고 재사용가능한 코드를 작성할 수 있다.  \n`LightningDataModule`은 train / val / test / prediction dataloader의 collection이며 각 단계에 해당하는 download, preprocessing, transform을 함께 정의한다.\n\n1. `prepare_data()`: single process에서 진행돼야하는 작업을 정의한다. (data download, tokenize)\n2. `setup`: 각 GPU에서 개별적으로 실시돼야하는 operation을 정의한다. (data split, create dataset, apply transform)\n3. `x_dataloader`: 각 stage별로 dataset -\u003e dataloader를 반환하는 코드를 작성한다.\n\n```python\nimport pytorch_lightning as pl\nfrom torch.utils.data import random_split, DataLoader\n\n# Note - you must have torchvision installed for this example\nfrom torchvision.datasets import MNIST\nfrom torchvision import transforms\n\n\nclass MNISTDataModule(pl.LightningDataModule):\n    def __init__(self, data_dir: str = \"./\"):\n        super().__init__()\n        self.data_dir = data_dir\n        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n\n    def prepare_data(self):\n        # download\n        MNIST(self.data_dir, train=True, download=True)\n        MNIST(self.data_dir, train=False, download=True)\n\n    def setup(self, stage: Optional[str] = None):\n\n        # Assign train/val datasets for use in dataloaders\n        if stage in (\"fit\", \"validate\", None):\n            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n\n        # Assign test dataset for use in dataloader(s)\n        if stage in (\"test\", None):\n            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n\n        if stage in (\"predict\", None):\n            self.mnist_predict = MNIST(self.data_dir, train=False, transform=self.transform)\n\n    def train_dataloader(self):\n        return DataLoader(self.mnist_train, batch_size=32)\n\n    def val_dataloader(self):\n        return DataLoader(self.mnist_val, batch_size=32)\n\n    def test_dataloader(self):\n        return DataLoader(self.mnist_test, batch_size=32)\n\n    def predict_dataloader(self):\n        return DataLoader(self.mnist_predict, batch_size=32)\n```\n\n## Weights \u0026 Biases 연동하기\n\npytorch lightning은 자체적으로 `WandbLogger`를 지원하므로 간단하게 logging, model 저장을 할 수 있다.  \n[W\u0026B 공식 post](https://wandb.ai/wandb_fc/korean/reports/Weights-Biases-Pytorch-Lightning---VmlldzozNzAxOTg)에 필요한 내용과 code들이 수록돼있으니 참고해서 작성하자.\n\n## 도움될 document 모음\n\n[prototyping에 사용하기 좋은 template colab notebook](https://colab.research.google.com/drive/1rHBxrtopwtF8iLpmC_e7yl3TeDGrseJL?usp=sharing%3E)  \n[early stopping을 사용하는 경우 callback 등록](https://pytorch-lightning.readthedocs.io/en/stable/common/early_stopping.html)  \n[GAN에서 여러 optimizer를 순서대로 실행시키는 경우](https://pytorch-lightning.readthedocs.io/en/stable/common/optimization.html#id4)  \n[자동으로 최대 batch size 찾기](https://pytorch-lightning.readthedocs.io/en/stable/advanced/training_tricks.html#batch-size-finder)  \n[자동으로 learning rate 찾기](https://pytorch-lightning.readthedocs.io/en/stable/advanced/training_tricks.html#learning-rate-finder)\n"}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"pytorch-lightning"},"buildId":"VaUQGDqs_MWm1pJur4D7C","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>